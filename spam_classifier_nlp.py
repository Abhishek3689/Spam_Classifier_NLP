# -*- coding: utf-8 -*-
"""Spam_Classifier_NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g_m4Q72jzF9kdmkBLAgdHZW511k6-cka
"""

# from google.colab import drive
# drive.mount('/content/drive')

import pandas as pd

import nltk

# nltk.download('all')

from nltk.stem import PorterStemmer
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords

import re

df=pd.read_csv("/content/drive/MyDrive/data/smsspamcollection/SMSSpamCollection",delimiter='\t',names=['label','messages'])

df.head()

df.shape

y=df['label']
x=df['messages']

y=pd.get_dummies(y) ## Applying one hot encoding

y.head()

y=y.drop('ham',axis=1) ## we can select any one as dependent variable,here selecting spam by droping ham

y.head()

x.head()

wordnet=WordNetLemmatizer()

corpus=[]
for i in range(len(x)):
  review=re.sub('^a-zA-Z',' ',x[i])
  review=review.lower()
  review=review.split()
  review=[wordnet.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]
  review=" ".join(review)
  corpus.append(review)

## Creating Bag of Words Model

from sklearn.feature_extraction.text import CountVectorizer

cv=CountVectorizer()

X=cv.fit_transform(corpus).toarray()

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=.2,random_state=34,stratify=y)

## Train model using Naive_Bayes Cassifier

from sklearn.naive_bayes import MultinomialNB

MNB=MultinomialNB()

MNB.fit(x_train,y_train)

y_pred=MNB.predict(x_test)

### Test Performance and Accuracy

from sklearn.metrics import accuracy_score,classification_report,confusion_matrix

confusion_matrix(y_test,y_pred)

accuracy_score(y_test,y_pred)

print(classification_report(y_test,y_pred))

y_pred[:10]





